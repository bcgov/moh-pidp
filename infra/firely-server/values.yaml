# Default values for Firely Server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: mage-registry.openshift-image-registry.svc:5000/d8a8f9-tools/firely-server
    # Overrides the image tag whose default is the chart appVersion.
  tag: latest
  pullPolicy: Always

# Put here the contents of appsettings.json
vonksettings: 
  {}
    
# Put here the contents of logsettings.json
logsettings:
  {}

license:
  secretName: firelyserver-license-secret
  fileName: firelyserver-license.json
  mountPath: /app # the path where the license file is mounted
  mountedFromExtraVolumes: false # if true, the license file is mounted from an extra volume
  value: # a valid license
  requestInfoFile: # ./.firelyserver-request-info.json
  writeRequestInfoFileInterval: # 15 // in minutes

# The name of a secret in the same kubernetes namespace which contains values to
# be added to the environment (must be manually created)
# This can be useful for connection strings, etc.
# For example, run the following to create a secret containing a connection string for MSSQL: 
# kubectl create secret generic -n ${FS_NAMESPACE} vonk-env-secret --from-literal=VONK_SqlDbOptions__ConnectionString='User Id=...'
envFromSecret: ""

# An array of environment variables expressed as key-value pair, name and value, to add to the container
extraEnvs: []

## Custom volumes
extraVolumes: []
#   - name: keyvault-secrets-store
#     csi:
#       driver: secrets-store.csi.k8s.io
#       readOnly: true
#       volumeAttributes:
#         secretProviderClass: "firely-keyvault"

## Custom volume mounts
extraMountPoints: []
#   - name: keyvault-secrets-store
#     mountPath: /mnt/keyvault_secrets_store
#     readOnly: true

plugins: []
#- url: <fully qualified url to plugin dll>
#  checksum: <a sha256 hash of the plugin dll file>

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # runAsNonRoot: true
  # runAsUser: 1000
  # runAsGroup: 2000
  # allowPrivilegeEscalation: false
  # privileged: false

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
  className: nginx
  certIssuer: letsencrypt-production
  path: /
  pathType: Prefix
  hosts: []
  #  - chart-example.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

persistence:
   enabled: false
#   existingPVClaim:

# Readiness probe
readinessProbe:
  httpGet:
    path: /$readiness
    port: http
  initialDelaySeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3
  periodSeconds: 10
  successThreshold: 1

# Liveness probe
livenessProbe:
  httpGet:
    path: /$liveness
    port: http
  initialDelaySeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
  periodSeconds: 120
  successThreshold: 1

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

validation:
  enabled: false
  replicaCount: 1
  image:
    registry: firely.azurecr.io
    repository: firely/firely-cloud-components
    tag: latest
    pullPolicy: IfNotPresent
  port: 8080
  persistence:
    carfilePVClaim: 
  resources: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []


# Put here the contents of appsettings.json for the validation component
validationsettings: 
  {
  } 



influxdb2:
  enabled: false
  # Additional configuration, See https://github.com/influxdata/helm-charts/blob/master/charts/influxdb2/values.yaml
  livenessProbe:
    path: "/health"
    scheme: "HTTP"
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 3
  
  readinessProbe:
    path: "/health"
    scheme: "HTTP"
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  
  startupProbe:
    enabled: true
    path: "/health"
    scheme: "HTTP"
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 1
    failureThreshold: 6
  
telegraf:
  enabled: false
  # Additional configuration, See https://github.com/influxdata/helm-charts/blob/master/charts/telegraf/values.yaml
  config:
    agent:
      interval: "10s"
      round_interval: true
      metric_batch_size: 1000
      metric_buffer_limit: 10000
      collection_jitter: "0s"
      flush_interval: "10s"
      flush_jitter: "0s"
      precision: ""
      debug: true
    inputs:
      - opentelemetry:
          service_address: ":4311" #address to receive traces
          timeout: "5s"
          metrics_schema: "prometheus-v2"
    processors:
      - starlark:
          source:
            |
              load("json.star", "json")
              load("logging.star", "log")
              def apply(metric):
                  log.info("Processing metric: {}".format(metric))
                  if "attributes" in metric.fields:
                      attrs_json = metric.fields["attributes"]
                      attrs = json.decode(attrs_json)
                      # if it is a request move measurment to requests collection
                      if "scope" in attrs and attrs["scope"] == "request":
                          metric.name = "requests"
                          attrs.pop("scope") # remove scope from attributes
                      else:
                          return None #if it is not a request, drop it
                      # copy attributes to tags and drop
                      for k, v in attrs.items():
                          metric.tags[k] = str(v)
                      metric.fields.pop("attributes")
                      # Collect only duration field and drop the rest
                      fields_to_remove = [field for field in metric.fields if field != "duration_nano"]

                      # Drop unwanted fields
                      for field in fields_to_remove:
                        metric.fields.pop(field)
                  else: 
                      return None #if there are no attributes, drop this trace
                  return metric
    outputs:
      - influxdb_v2:
          urls: 
            - "${INFLUXDB_URL}"
          organization: "${INFLUXDB_ORG}"
          bucket: "${INFLUXDB_BUCKET}"
          token: "${INFLUXDB_WRITE_TOKEN}"
          timeout: "5s"

opentelemetry-collector:
  enabled: false
  # Additional configuration. See https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-collector/values.yaml
  mode: "deployment"
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 1000m

  image:
    repository: "otel/opentelemetry-collector-contrib"

  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318


    exporters:
      otlp/telegraf:
        endpoint: ${env:TELEGRAF_ENDOINT}
        tls:
          insecure: true

    #  otlphttp:
    #    endpoint: http://seq.seq.svc.cluster.local/ingest/otlp

    processors:
      batch: {}
      filter/health: #https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor
        error_mode: ignore
        traces:
          span:
            - 'attributes["url.path"] == "/$$liveness"'
            - 'attributes["url.path"] == "/$$readiness"'
      filter/requestmeter:
        spans:
          include:
            match_type: strict
            attributes:
              - key: "scope"
                value: "request"

    service:
      pipelines:
        #traces:
        #  receivers: [otlp]
        #  exporters: [otlphttp]
        #  processors: [filter/health, batch]
        traces/requestmeter:
          receivers: [otlp]
          exporters: [otlp/telegraf]
          processors: [filter/health, filter/requestmeter, batch]


